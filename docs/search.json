[
  {
    "objectID": "learning_posts/statistics.html",
    "href": "learning_posts/statistics.html",
    "title": "Statistics",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "learning_posts/statistics/correlation.html",
    "href": "learning_posts/statistics/correlation.html",
    "title": "Correlation",
    "section": "",
    "text": "In many data-driven contexts, we become interested in understanding the relationship between two variables.\nFor example, let’s say we’ve run an experiment to test the effect of a novel drug on immune cell function. To test this drug, we treat 20 cultured dishes of immune cells (\\(n = 20\\)) with a single dose. As an outcome, we measure the concentration of two proteins from the treated cells: protein A and protein B.\nWhen we evaluate the results from the experiment, we can imagine different possible outcomes of the concentrations of proteins A and B in relation to one another:\n\nAs protein A concentration increases, protein B concentration also increases\nAs protein A concentration increases, protein B concentration does not change\nAs protein A concentration increases protein B concentration decreases\netc…\n\nAs you may have gathered, an important nuance of this example is that we are not particularly interested in understanding whether the concentration of protein A causes the concentration of protein B to change, or vice versa. Instead, we only want to evaluate how their concentrations change in relation to one another. This type of non-causal evaluation is symmetric in nature.\nTo evaluate symmetric relationships between two variables, one can examine their correlation. Formally, correlation is a measurement of the the strength, and sometimes direction, of a relationship between two variables1. When two variables are related to one another, such as in cases 1 and 3 from our example above, we say that they are correlated.\nImportantly, even if two variables are correlated, we can not use this correlation to make any assumptions about the causal nature of their relationship, begging the adage: correlation \\(\\neq\\) causation.\nRegardless of whether the relationship between two variables is causal or not, correlation statistics still provide an indication of underlying relationships between\nOften you will see that correlation tests evaluate linear relationships, but some correlation tests evaluate non-linear relationships as well."
  },
  {
    "objectID": "learning_posts/statistics/correlation.html#overview",
    "href": "learning_posts/statistics/correlation.html#overview",
    "title": "Correlation",
    "section": "",
    "text": "In many data-driven contexts, we become interested in understanding the relationship between two variables.\nFor example, let’s say we’ve run an experiment to test the effect of a novel drug on immune cell function. To test this drug, we treat 20 cultured dishes of immune cells (\\(n = 20\\)) with a single dose. As an outcome, we measure the concentration of two proteins from the treated cells: protein A and protein B.\nWhen we evaluate the results from the experiment, we can imagine different possible outcomes of the concentrations of proteins A and B in relation to one another:\n\nAs protein A concentration increases, protein B concentration also increases\nAs protein A concentration increases, protein B concentration does not change\nAs protein A concentration increases protein B concentration decreases\netc…\n\nAs you may have gathered, an important nuance of this example is that we are not particularly interested in understanding whether the concentration of protein A causes the concentration of protein B to change, or vice versa. Instead, we only want to evaluate how their concentrations change in relation to one another. This type of non-causal evaluation is symmetric in nature.\nTo evaluate symmetric relationships between two variables, one can examine their correlation. Formally, correlation is a measurement of the the strength, and sometimes direction, of a relationship between two variables1. When two variables are related to one another, such as in cases 1 and 3 from our example above, we say that they are correlated.\nImportantly, even if two variables are correlated, we can not use this correlation to make any assumptions about the causal nature of their relationship, begging the adage: correlation \\(\\neq\\) causation.\nRegardless of whether the relationship between two variables is causal or not, correlation statistics still provide an indication of underlying relationships between\nOften you will see that correlation tests evaluate linear relationships, but some correlation tests evaluate non-linear relationships as well."
  },
  {
    "objectID": "learning_posts/statistics/correlation.html#correlation-statistics",
    "href": "learning_posts/statistics/correlation.html#correlation-statistics",
    "title": "Correlation",
    "section": "Correlation Statistics",
    "text": "Correlation Statistics\n\nCoefficients\nThe output of a correlation analysis is a correlation statistic. This statistic will usually fall in the range of \\(-1\\) to \\(1\\), although depending on the test used, it can sometimes fall between \\(0\\) and \\(1\\).\n\n\nP Values"
  },
  {
    "objectID": "learning_posts/statistics/correlation.html#correlation-methods",
    "href": "learning_posts/statistics/correlation.html#correlation-methods",
    "title": "Correlation",
    "section": "Correlation Methods",
    "text": "Correlation Methods\nThe next sections of the site contain overviews of several correlation tests. Each method has its own set of strengths and weakness, as well as assumptions that must be met before it can be used.\nFor example, we would use a Pearson test to evaluate parametric correlations, and the Spearman test to evaluate non-parametric correlations.\n\nPearson Correlation\nSpearman Rank-Order Correlation\nKendall Rank Correlation\nPoint-Biserial Correlation\nDistance Correlation"
  },
  {
    "objectID": "learning_posts/linear_algebra/rank.html",
    "href": "learning_posts/linear_algebra/rank.html",
    "title": "Matrix Rank",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "About\nMy name is Jacob Bumgarner. I’m computational biologist with a passion for building and writing.\nPlease feel free to connect with me through the links above.\n\n\nCareer\nI am currently a computational biologist specializing in reverse translational and predictive sciences for drug development. I work to expand our understanding of the mechanisms that drive neurodegenerative and autoimmune diseases.\nMy experience encompasses computational biology, bioinformatics, software engineering, and machine learning. I am driven by a passion for problem-solving and applying my skills to improve human health.\n\n\nEducation\nPrior to starting my career, I completed my Ph.D. in Neuroscience at West Virginia University from 2019-2023, where I studied circadian rhythms, pain, and cerebrovasculature in Randy Nelson’s lab.\nBefore that, I was a completed my B.M. (Bachelor of Music) from 2015-2019 at West Virginia University, where I studied piano performance with Ching-Wen Hsiao and learned the ropes of biomedical research in Paul Lockman’s lab.\n\n\n\n Back to top"
  },
  {
    "objectID": "learning.html",
    "href": "learning.html",
    "title": "Learning Collection",
    "section": "",
    "text": "Construction in progress… \nWelcome to my learning collection. The educational articles in this collection were created for the educational benefit of myself and others.\n\nOverview\nEach article is created with the Feynman technique in mind, drawing inspiration from expert educators, including Grant Sanderson, Steve Mould, Gilbert Strang, and Destin Sandlin.\nBy writing these articles, I hope to distill the fundamental gist of each topic such that anyone can understand them. Of course, the topics I cover aren’t exhaustive and aren’t meant to replace textbooks or other online learning mediums. Instead, I hope they act as foundations for the introduction to topics or supplemental materials for the mastery of topics.\n\n\nTopics\nBelow is a list of the topics with covered material. Many of these topics have sub-sections, which can be opened by clicking the dropdown arrows.\n\nStatistics\nLinear Algebra\nMachine Learning\nDeep Learning\nBioinformatics\n\n\n\nResources\nBelow is a list of the resources I use to create these articles.\n\nManim\nCiteDrive\nQuarto\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "learning_posts/linear_algebra.html",
    "href": "learning_posts/linear_algebra.html",
    "title": "Linear Algebra",
    "section": "",
    "text": "This section is all about linear algebra.\nThanks to Gilbert Strang.\n\n\n\n Back to top"
  },
  {
    "objectID": "learning_posts/linear_algebra/vectors.html",
    "href": "learning_posts/linear_algebra/vectors.html",
    "title": "Vectors",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "learning_posts/statistics/variance/variance.html",
    "href": "learning_posts/statistics/variance/variance.html",
    "title": "Variance - Draft",
    "section": "",
    "text": "Variance is a quantitative measurement of the spread of a set of data around the mean of the data.\nWe can use variance to describe the two different distributions shown in the figure below. The orange distribution has a larger variance than the red distribution because the sample data are more spread out around the mean.\n\n\n\nVarying Distributions\n\n\nThere are two formal ways to define variance. Emperically, variance describes the distribution of observed data collected from a sample or population. Theoretically, variance describes the probability distribution of a random variablea.\n\n\naRandom variables are functions that map sample spaces (e.g., \\(\\{ H, T \\}\\) is the sample space of a coin flip) to a measurable space (e.g., \\(\\{ H: 0, T: 1\n\\}\\)). By definition, a random variable generates values that vary randomly1,2.\nIn this article, we’ll review the relationship between the two definitions of variance, but we’ll focus on the empirical definition. We’ll also discuss how variance is calculated and how it can be used to describe the spread of data."
  },
  {
    "objectID": "learning_posts/statistics/variance/variance.html#overview",
    "href": "learning_posts/statistics/variance/variance.html#overview",
    "title": "Variance - Draft",
    "section": "",
    "text": "Variance is a quantitative measurement of the spread of a set of data around the mean of the data.\nWe can use variance to describe the two different distributions shown in the figure below. The orange distribution has a larger variance than the red distribution because the sample data are more spread out around the mean.\n\n\n\nVarying Distributions\n\n\nThere are two formal ways to define variance. Emperically, variance describes the distribution of observed data collected from a sample or population. Theoretically, variance describes the probability distribution of a random variablea.\n\n\naRandom variables are functions that map sample spaces (e.g., \\(\\{ H, T \\}\\) is the sample space of a coin flip) to a measurable space (e.g., \\(\\{ H: 0, T: 1\n\\}\\)). By definition, a random variable generates values that vary randomly1,2.\nIn this article, we’ll review the relationship between the two definitions of variance, but we’ll focus on the empirical definition. We’ll also discuss how variance is calculated and how it can be used to describe the spread of data."
  },
  {
    "objectID": "learning_posts/statistics/variance/variance.html#calculating-variance",
    "href": "learning_posts/statistics/variance/variance.html#calculating-variance",
    "title": "Variance - Draft",
    "section": "Calculating Variance",
    "text": "Calculating Variance\n Construction in progress…"
  },
  {
    "objectID": "learning_posts/statistics/variance/variance.html#references",
    "href": "learning_posts/statistics/variance/variance.html#references",
    "title": "Variance - Draft",
    "section": "References",
    "text": "References\n\n\n1. Wikipedia. (2024). Random variable — Wikipedia, the free encyclopedia. http://en.wikipedia.org/w/index.php?title=Random%20variable.\n\n\n2. 3.1 - Random Variables  STAT 500. (2024). https://online.stat.psu.edu/stat500/lesson/3/3.1"
  }
]